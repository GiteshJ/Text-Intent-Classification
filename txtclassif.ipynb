{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    \n",
    "    df_confusion = pd.crosstab(y_actu, y_pred.reshape(y_pred.shape[0],), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    \n",
    "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "    \n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)\n",
    "def predict(X, Y, W, b, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data containing sentences, numpy array of shape (m, None)\n",
    "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "    pred -- numpy array of shape (m, 1) with your predictions\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    pred = np.zeros((m, 1))\n",
    "    \n",
    "    for j in range(m):                       # Loop over training examples\n",
    "        \n",
    "        # Split jth test example (sentence) into list of lower case words\n",
    "        words = X[j].lower().split()\n",
    "        \n",
    "        # Average words' vectors\n",
    "        avg = np.zeros((50,))\n",
    "        for w in words:\n",
    "            avg += word_to_vec_map[w]\n",
    "        avg = avg/len(words)\n",
    "\n",
    "        # Forward propagation\n",
    "        Z = np.dot(W, avg) + b\n",
    "        A = softmax(Z)\n",
    "        pred[j] = np.argmax(A)\n",
    "        \n",
    "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))))\n",
    "    \n",
    "    return pred\n",
    "def print_predictions(X, pred):\n",
    "    print()\n",
    "    for i in range(X.shape[0]):\n",
    "        print(X[i], label_to_emoji(int(pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('dataset.csv')\n",
    "X_test, Y_test = read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM NOT ABLE TO MAKE PAYMENT THROUGH MY DEBIT OR CREDIT CARD . AN ERROR MESSAGE WAS SHOWN THAT \" THIS CARD IS NOT RECOGNISED \" . 0\n"
     ]
    }
   ],
   "source": [
    "index = 11\n",
    "print(X_train[index], Y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 3)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n",
      "[ 0.68224  -0.31608  -0.95201   0.47108   0.56571   0.13151   0.22457\n",
      "  0.094995 -1.3237   -0.51545  -0.39337   0.88488   0.93826   0.22931\n",
      "  0.088624 -0.53908   0.23396   0.73245  -0.019123 -0.26552  -0.40433\n",
      " -1.5832    1.1316    0.4419   -0.48218   0.4828    0.14938   1.1245\n",
      "  1.0159   -0.50213   0.83831  -0.31303   0.083242  1.7161    0.15024\n",
      "  1.0324   -1.5005    0.62348   0.54508  -0.88484   0.53279  -0.085119\n",
      "  0.02141  -0.56629   1.1463    0.6464    0.78318  -0.067662  0.22884\n",
      " -0.042453]\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n",
    "print(word_to_vec_map['cucumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sentence_to_avg\n",
    "\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Split sentence into list of lower case words (≈ 1 line)\n",
    "    words = [i.lower() for i in sentence.split()]\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros((50,))\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = avg / len(words)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [ 9.79850345e-02  6.93903255e-02  7.25572103e-02 -2.08946586e-01\n",
      "  2.75334507e-01  1.13997762e-01 -4.29399655e-01  9.09981034e-03\n",
      " -1.38489042e-01  2.66702103e-03  1.36158241e-01  2.53767952e-01\n",
      " -3.89884138e-01 -1.53686724e-01  6.51387224e-01  2.87995717e-01\n",
      " -4.88895172e-02 -1.67267034e-01 -1.02404000e-01 -4.59334241e-01\n",
      "  9.36202414e-02  1.57892414e-02  1.86638966e-01 -3.98122759e-02\n",
      "  5.77247931e-02 -1.60734345e+00 -3.42556352e-01 -5.60501379e-02\n",
      "  2.02296241e-01 -3.38956000e-01  3.18666207e+00  3.20533324e-01\n",
      " -3.49764448e-01 -2.22568879e-01  1.52854694e-01 -5.15690552e-02\n",
      "  3.21971690e-01  2.53166172e-01  1.12600124e-01 -3.92765207e-01\n",
      " -1.10599441e-01 -5.53567241e-02  6.32271448e-02  3.52763621e-01\n",
      " -2.59805793e-01 -1.14892503e-01 -5.03173828e-02  1.94792834e-01\n",
      "  3.76594828e-02  1.22308076e-01]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"I APPLIED FOR A CREDIT CARD LAST MONTH BUT I DID NOT GET THAT ONE TILL NOW ALTHOUGH I FULLFILL ALL THE CRITERIA REQUIRED FOR APPLYING CREDIT CARD .\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = read_csv('train.csv')\n",
    "X_test, Y_test = read_csv('test.csv')\n",
    "for i in range(X_train.shape[0]):\n",
    "    print(i)\n",
    "    avg = sentence_to_avg(X_train[i], word_to_vec_map)\n",
    "    #print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 150):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Define number of training examples\n",
    "    m = Y.shape[0]                          # number of training examples\n",
    "    n_y = 3                                 # number of classes  \n",
    "    n_h = 50                                # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Convert Y to Y_onehot with n_y classes\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations):                       # Loop over the number of iterations\n",
    "        for i in range(m):                                # Loop over the training examples\n",
    "            \n",
    "            ### START CODE HERE ### (≈ 4 lines of code)\n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
    "            cost = -np.sum(np.multiply(Y_oh[i], np.log(a)))\n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79,)\n",
      "(79,)\n",
      "(79, 3)\n",
      "I APPLIED FOR A CREDIT CARD LAST MONTH BUT I DID NOT GET THAT ONE TILL NOW . ALTHOUGH I FULLFILL ALL THE CRITERIA REQUIRED FOR APPLYING CREDIT CARD .\n",
      "<class 'numpy.ndarray'>\n",
      "(79, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(3)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "print(np.eye(3)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 0.9824050052952049\n",
      "Accuracy: 0.4177215189873418\n",
      "Epoch: 100 --- cost = 0.5079142560624624\n",
      "Accuracy: 0.9493670886075949\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9620253164556962\n",
      "Test set:\n",
      "Accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "#Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "#pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "#print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21,)\n",
      "            0      1      2     \n",
      "Predicted  0.0  1.0  2.0  All\n",
      "Actual                       \n",
      "0            8    1    0    9\n",
      "1            0    5    0    5\n",
      "2            4    1    2    7\n",
      "All         12    7    2   21\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAD3CAYAAADYInvcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cec87c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ ' 0 '+ '    ' + ' 1 ' + '    ' +  ' 2 '+ '    ')\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(21,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
